{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentação e criação do vetor de características\n",
    "\n",
    "**Observação inicial**: para os trabalhos posteriores, será levado em consideração que os dados estão corretos e filtrados conforme na aula de \"Pré-processamento\". Portando, antes de iniciar este conteúdo, vocês terão que ter concluído as questões passadas e como **tarefa** salvar um arquivo com dados filtrados (não executar todo `preprocessing.ipynb`).\n",
    "\n",
    "Serão utilizados nesta aula os dados sem nenhuma filtragem e com o conjunto de canais escolhidos aleatoriamente.\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Um formato importante do *dataset* para a classificação dos dados, é estar organizado preferencialmente em duas dimensões. As linhas serão as amostras (rotuladas ou não) e as colunas, as características. Além disso, os dados para cada uma das características deve fazer algum sentido para a boa atuação do classificador. Para essa matriz final, damos o nome de `vetor de características`.\n",
    "\n",
    "Em experimentos SSVEP-BCI, a característica mais forte é o `PSD` (*Power Spectral Density*). O `PSD`, como o nome sugere, é obtido por meio do sinal no domínio da frequência, aplicando a seguinte fórmula: $|x_i|^2$. O `PSD` potencializa a energia das frequências mais evidentes, melhorando o desempenho de classificação.\n",
    "\n",
    "Alguns métodos da biblioteca MNE nos dão um vetor de características pronto. Porém, é interessante realizarmos algumas etapas passo a passo sem o uso inicial da biblioteca para entendermos o funcionamento do método e alterar como quisermos.\n",
    "\n",
    "\n",
    "## Transformação de domínio (e segmentação)\n",
    "\n",
    "O `shape` inicial dos dados é: `(125, 256, 1205) -> (trials, channels, data)`. Vamos aplicar a Transformada Rápida de Fourier em Tempo Curto (STFT) (após carregar e filtrar os dados):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import mne\n",
    "from scipy.signal import stft\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files/ssvep-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    4995.85 ms\n",
      "        0 CTF compensation matrices available\n",
      "125 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "<EpochsFIF  |   125 events (all good), 0 - 4.99585 sec, baseline off, ~15.1 MB, data loaded,\n",
      " '1': 25\n",
      " '2': 25\n",
      " '3': 30\n",
      " '4': 25\n",
      " '5': 20>\n"
     ]
    }
   ],
   "source": [
    "# carregamento do dataset (FIF file)\n",
    "epochs = mne.read_epochs('files/ssvep-epo.fif')\n",
    "# filtranndo apenas alguns canais\n",
    "epochs.pick_channels(['E108', 'E109', 'E116', 'E125', 'E118', 'E117', 'E126',\n",
    "                      'E139', 'E127', 'E138', 'E140', 'E150', 'E151'])\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 13, 1205)\n",
      "(125, 13, 17, 77)\n"
     ]
    }
   ],
   "source": [
    "# extraindo somente os dados do objeto MNE\n",
    "data = epochs.get_data()\n",
    "print(data.shape) # domínio do tempo\n",
    "\n",
    "# aplicando STFT\n",
    "_, _, w = stft(data, fs=241, nperseg=32, noverlap=16)\n",
    "# w = np.swapaxes(w, 3, 4)\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obemos um `shape` diferente, acrescentando uma dimensão a mais em nossos dados. Isso é devido a quantidade de janelas ou segmentos informados (`nperseg`) e a sobreposição utilizada (`overlap`). **DISCUSSÃO EM AULA**\n",
    "\n",
    "Aplicando o `PSD` teremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 13, 17, 77)\n"
     ]
    }
   ],
   "source": [
    "W = np.abs(w) ** 2\n",
    "# w = np.reshape(w, (125, 13, 17 * 77)) # <= questão de projeto\n",
    "# w = w.transpose(0, 2, 1)\n",
    "# w = np.reshape(w, (125 * 1309, 13))\n",
    "print(W.shape)\n",
    "\n",
    "# shape resultante: (125, 13, 17, 77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração de características\n",
    "\n",
    "Não é uma boa estratégia utilizar os dados \"crus\" de `PSD` para a classificação. Desta forma, vamos adotar alguns algoritmos simples para reduzir uma dimensão dos dados e potencializar nossas características. Uma lista de característica é listada [por este artigo intitulado \"*A wearable wireless brain-computer interface using steady-state visual evoked potentials*\"](https://www.researchgate.net/publication/334854837_A_wearable_wireless_brain-computer_interface_using_steady-state_visual_evoked_potentials). Já que temos o PSD dos dados, vamos demonstrar a aplicação do \"*Mean of PSD*\" ou `FMN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMN: (125, 13, 17)\n",
      "RSS: (125, 13, 17)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fmn = np.mean(W, axis=-1)\n",
    "print('FMN:', fmn.shape)\n",
    "\n",
    "# Root of sum of squares\n",
    "rss = np.sqrt(np.sum(W, axis=-1))\n",
    "print('RSS:', rss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a aplicação de algumas características, juntamos todas elas no mesmo conjunto de dados e transformamos cada eletrodo em uma característica. Em outras palavras, o *shape* final que ficou no seguinte formato:`(125, 13, 17)`. Agora deverá ficar `(125 * 17, 13) => (2125, 13)`.\n",
    "\n",
    "Se mais características fossem adicionadas, elas entrariam como multiplicação nas colunas. No exemplo anterior temos apenas uma característica desenvolvida. Se adicionarmos 4 características, o `shape` do vetor de características ficaria no seguinte formato: `(2125, 13 * 4) => (2125, 52)`. Explicando os dados, seriam 2125 amostras e 52 características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos dados: (2125, 26)\n"
     ]
    }
   ],
   "source": [
    "# realização das transformações finais (TAREFA)\n",
    "\n",
    "# finalizando o exemplo com a junção das duas características criadas\n",
    "features = list()\n",
    "for feature in (fmn, rss,):\n",
    "    feature = feature.transpose(0, 2, 1)\n",
    "    feature = feature.reshape(feature.shape[0] * feature.shape[1],\n",
    "                              feature.shape[2])\n",
    "    features.append(feature)\n",
    "\n",
    "# vetor de características final\n",
    "X = np.concatenate(features, axis=-1)\n",
    "print('Shape dos dados:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptação do vetor de *labels*\n",
    "\n",
    "Temos que adaptar o vetor de *labels* para ficar do mesmo tamanho (mesma quantidade de linhas) que o vetor de dados `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape original dos labels (125,)\n",
      "Shape final dos labels (2125,)\n"
     ]
    }
   ],
   "source": [
    "y = np.load('files/labels.npy')\n",
    "print('Shape original dos labels', y.shape)\n",
    "\n",
    "size = int(X.shape[0] / y.shape[0])\n",
    "y = np.concatenate([y for i in range(size)])\n",
    "print('Shape final dos labels', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questões de projeto\n",
    "\n",
    "1) Nem sempre os canais são vistos como características. Uma outra forma é adicionar os canais às amostras (reduzindo a quantidade de características e aumentando a quantidade de amostras). O resultado disso deve ser avaliado.\n",
    "\n",
    "2) É comum a aplicação de algum algoritmo para reduzir todos os canais ou transformar apenas em um (que é o caso de aplicar a média de todos os eletrodos/canais).\n",
    "\n",
    "3) Adicionar características ruins confundem o resultado? Características que não estão relacionadas ao domínio do problema pode ser ruim? Isso deve ser avaliado..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resposta das questões: \n",
    "    https://github.com/spacexjedi/data-science-101/blob/master/MAMEM_SSVEP/RP_homework/features.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
