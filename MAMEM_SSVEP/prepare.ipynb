{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação do *dataset* de trabalho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este *notebook* tem como objetivo preparar uma parte específica (de escolha do usuário) para o *dataset* MAMEM SSVEP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bloco apenas com organizações de imports\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** O arquivo `requirements.txt` foi adicionado à pasta do GitHub.\n",
    "Para instalar todos os requerimentos necessários (no linux), basta fazer:\n",
    "\n",
    "```\n",
    "$ pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bloco de declaração dos identificadores de download (google drive) e setup\n",
    "dataset_ids = {\n",
    "    1: '1ym3JqI4_ZYNSBLxoF1vNxI5Hsgur_tha',\n",
    "    2: '1tJ5tHbE-2jwr0gA33Gd873lRPao-e4dF',\n",
    "    3: '1tXdpY-mser01POaP6Qwixny6LjsXXoXB',\n",
    "    4: '1T00cliWp5yqqbbWZ7-rf2X4tOUQ-PvIQ',\n",
    "    5: '1CYsBFMul9zB_vCy0XD7XVfKUl8vihDYZ',\n",
    "    6: '1io6jdALBKeopELWXahPzuAi6EfYDgviW',\n",
    "    7: '1YDkheRDPNDR1ujsqqC_SY6cebWHkw9Xt',\n",
    "    8: '1jjoQJFDCi7O9Q-iaReAPpQnxC-HIKpQi',\n",
    "}\n",
    "label_id = '1mD5MXoh6tfQJFXIvdw2MQsEu6vZka6C0'\n",
    "desc = '14kYNBZYdttqmSS_Vz6Bm_ztG9Uw1MC0y'\n",
    "\n",
    "# ALTERE O ID DO DATASET DE SUA ESCOLHA AQUI ##################################\n",
    "DS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funções de download abaixo não realizam o download mais de uma vez se o arquivo já existe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download do stataset\n",
    "gdd.download_file_from_google_drive(file_id=dataset_ids[DS],\n",
    "                                    dest_path='files/data.npy',\n",
    "                                    showsize=True)\n",
    "# download do arquivo de marcações\n",
    "gdd.download_file_from_google_drive(file_id=label_id,\n",
    "                                    dest_path='files/labels.npy', showsize=True)\n",
    "\n",
    "# download do arquivo de descrição\n",
    "gdd.download_file_from_google_drive(file_id=desc,\n",
    "                                    dest_path='files/descriptor.json',\n",
    "                                    showsize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estruturas => dados (125, 257, 1205) labels (125,)\n"
     ]
    }
   ],
   "source": [
    "# carregamento\n",
    "X = np.load('files/data.npy')\n",
    "y = np.load('files/labels.npy')\n",
    "desc_file = open('files/descriptor.json')\n",
    "descriptor = json.loads(desc_file.read())\n",
    "desc_file.close()\n",
    "print('Estruturas => dados', X.shape, 'labels', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados estão estruturados em numpy arrays.\n",
    "\n",
    "O \"shape\" `(125, 257, 1205)` para os dados EEG de `X`, significa que existem 125 *trials* (tradução aceitável: ensaio, julgamento), 257 *channels* que representam os eletrodos e 1205 dados que representam o potencial mensurado em ponto flutuante. Este é um array com **três dimensões**.\n",
    "\n",
    "O \"shape\" `(125,)` para os dados de *labels* ou marcadores `y`, apresentam qual é o eletrodo respectivo a cada *trial*. Os *labels* estão com valores numéricos como é mostrado a seguir, o que facilita o processamento, mas não é intuitivo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 3, 5, 1, 2, 5, 4, 2, 3, 1, 5, 4, 3, 2, 4, 1, 2, 5, 3, 4, 1,\n",
       "       3, 1, 3, 4, 2, 3, 5, 1, 2, 5, 4, 2, 3, 1, 5, 4, 3, 2, 4, 1, 2, 5,\n",
       "       3, 4, 1, 3, 1, 3, 4, 2, 3, 5, 1, 2, 5, 4, 2, 3, 1, 5, 4, 3, 2, 4,\n",
       "       1, 2, 5, 3, 4, 1, 3, 1, 3, 4, 2, 3, 5, 1, 2, 5, 4, 2, 3, 1, 5, 4,\n",
       "       3, 2, 4, 1, 2, 5, 3, 4, 1, 3, 1, 3, 4, 2, 3, 5, 1, 2, 5, 4, 2, 3,\n",
       "       1, 5, 4, 3, 2, 4, 1, 2, 5, 3, 4, 1, 3, 1, 3], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta forma, foi preparado um arquivo de descrição no qual é possível saber qual é o rótulo correto do correspondente \"número\", além de outras informações como a taxa de amostragem (sampling rate), idade, tipo do cabelo (curto, médio ou comprido), sexo, tamanho da touca e se é destro ou canhoto. A princípio, imaginamos que estas informações não são tão importantes, mas problemas na experimentação podem ter culpa por um desses motivos, como por exemplo, o tamanho do cabelo. Veja os dados do voluntário escolhido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características do voluntário: {'age': '25', 'capsize': 'Adult Medium', 'gender': 'Male', 'hairtype': 'Regular', 'handedness': 'Right'}\n",
      "\n",
      "Rótulos: {'1': 6.66, '2': 7.5, '3': 8.57, '4': 10.0, '5': 12.0}\n",
      "\n",
      "Taxa de amostragem: 250\n"
     ]
    }
   ],
   "source": [
    "print('Características do voluntário:', descriptor[str(DS)])\n",
    "print('\\nRótulos:', descriptor['frequencies'])\n",
    "print('\\nTaxa de amostragem:', descriptor['sampling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como explicado em aula, apesar do autor do *dataset* apresentar a taxa de amostragem da captura dos dados igual a 250 Hz, o mesmo não foi verificado por meio dos dados. Os dados dos voluntários estão desbalanceados em quantidade, o que não nos permite criar um `numpy.array`, que permite apenas vetores não esparsos. Desta forma, teremos que recalcular a taxa de amostragem (*sample rate*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nova taxa de amostragem: 241.0 Hz\n"
     ]
    }
   ],
   "source": [
    "# quantidade_de_dados / tempo_do_trial\n",
    "descriptor['sampling_rate'] = X.shape[-1] / 5\n",
    "print('Nova taxa de amostragem: {} Hz'.format(descriptor['sampling_rate']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando um objeto estruturado EEG do *dataset*\n",
    "\n",
    "Neste ponto, iremos trabalhar com a biblioteca MNE. Ela nos permite além de estruturar melhor os dados:\n",
    "* Realizar o mapeamento dos eletrodos de acordo com o equipamento utilizado;\n",
    "* Filtrar canais de acordo com a necessidade do experimento;\n",
    "* Aplicar filtros temporais e espaciais;\n",
    "* Mostrar *plots* dinâmicos\n",
    "* Aplicar algoritmos de extração e seleção de características, entre outros...\n",
    "\n",
    "### Tarefas\n",
    "\n",
    "- Estudar a biblioteca MNE disponível [site oficial](https://mne.tools/stable/index.html)\n",
    "    - Um bom começo é ver por meio dos exemplos [\"Criando objetos MNE a partir de dados em vetores\"](https://mne.tools/stable/auto_examples/io/plot_objects_from_arrays.html#sphx-glr-auto-examples-io-plot-objects-from-arrays-py)\n",
    "- Ler o documento sobre o dataset de trabalho disponível [neste link](https://figshare.com/articles/MAMEM_EEG_SSVEP_Dataset_II_256_channels_11_subjects_5_frequencies_presented_simultaneously_/3153409) e obter algumas informações importantes como:\n",
    "    - Qual aparelho de EEG é utilizado;\n",
    "    - Se filtros temporais (*bandpass*, *lowpass*, *highpass*) já foram aplicados;\n",
    "    - Qual é a configuração da touca, que será utilizada para o setup do parâmetro `mount` no metadado de informações.\n",
    "    - Verificar se as características dos voluntários influenciaram no experimento;\n",
    "    - Entender a configuração do ambiente de experimento;\n",
    "    - além de outras informações relevantes para a nossa análise..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
